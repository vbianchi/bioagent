# Configuration settings for the BioAgent

# LLM Settings
llm_settings:
  # Model name from OpenAI (or adapt for Ollama later)
  model_name: "gpt-3.5-turbo"
  # Temperature for LLM calls (0 = deterministic, >0 = creative)
  temperature: 0

# Search Settings
search_settings:
  # Max results to fetch *per source* (PubMed, ArXiv)
  max_results_per_source: 3
  # Max abstracts to pass to the summarizer LLM
  max_abstracts_to_summarize: 3

# Prompt Templates (Use | for multi-line strings preserving newlines)
# Variables like {query}, {abstracts_text} will be inserted by the code
prompts:
  # For routing user input
  routing_prompt: |
    Classify the user's query into one of the following categories: 'literature_search' or 'chat'. Respond ONLY with the category name.

    - 'literature_search': The user is asking to find papers, articles, publications, search results, or specific information likely found by searching scientific literature databases (like PubMed or ArXiv). Keywords often include "find papers", "search for articles", "publications on", "literature about".
        Examples:
            "Find papers on CRISPR" -> literature_search
            "Search PubMed for gene editing" -> literature_search
            "What articles discuss LLMs in bioinformatics?" -> literature_search
            "Show me recent studies on vaccine effectiveness" -> literature_search

    - 'chat': The user is asking a general question, asking for a definition or explanation, making a statement, greeting, or having a conversation. These queries typically don't require searching literature databases directly. Keywords often include "what is", "explain", "tell me about", "hello", "hi", "can you". It might also refer to previous turns like "what did you find?".
        Examples:
            "Hello" -> chat
            "Explain what an LLM is" -> chat
            "What is bioinformatics?" -> chat
            "Tell me about DNA sequencing" -> chat
            "What did you find in the last search?" -> chat
            "Can you help me write some code?" -> chat

    User Query: "{query}"
    Classification:

  # For refining literature search queries
  refinement_prompt: |
    Given the user's query, extract the core topic or keywords suitable for searching scientific databases like PubMed and ArXiv. Focus on nouns, technical terms, and essential concepts. Remove conversational phrases like "find papers on", "search for", "tell me about". Respond ONLY with the refined search query string.

    User Query: "{query}"
    Refined Search Query:

  # For summarizing search result abstracts
  summarization_prompt: |
    Given the user's original query and the following abstracts from search results, provide a concise summary of the key findings relevant to the query.

    Original User Query: "{query}"

    Abstracts:
    ---
    {abstracts_text}
    ---

    Concise Summary:

  # For basic chat responses (can be enhanced)
  chat_prompt: |
    User query: {query}
    Assistant response: